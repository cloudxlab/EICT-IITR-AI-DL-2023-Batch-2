{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will make a simple CNN and train fashion MNIST with it. Fashion MNIST is like number MNIST, instead of numbers it has got images of wearables. The classes in Fashion MNIST are\n",
    "\n",
    "- 0 T-shirt/top\n",
    "- 1 Trouser\n",
    "- 2 Pullover\n",
    "- 3 Dress\n",
    "- 4 Coat\n",
    "- 5 Sandal\n",
    "- 6 Shirt\n",
    "- 7 Sneaker\n",
    "- 8 Bag\n",
    "- 9 Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "#This segment verifies the setup\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "IS_COLAB=0\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the following in this section\n",
    "- Load mnist data from Keras with train_full and test sets\n",
    "- Create train set and valid set\n",
    "- Normalise the input data\n",
    "- Add channel dimension to input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of full train and test sets (60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "item0 9\n",
      "Shape of train and valid sets (25000, 28, 28) (25000,) (5000, 28, 28) (5000,)\n",
      "Shape of features (25000, 28, 28, 1) (5000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD8CAYAAAC8aaJZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAUX0lEQVR4nO3df4yV9ZXH8feBGUWHQUAoVKmDoIDBlqYOcVsaNalLo0lbs6TZWrvZP9rS7IZ0k/7TmkhLqqRuNukfTbttyLrqGu2vBInVbGPayjb+oGVM1To6YFAHBZUZ+TkjDAyc/eNemuvAc77Dvc/Mve3380omgefM994zz3B47r3n+X6/5u6ISD6mNDsBEZlcKnqRzKjoRTKjohfJjIpeJDMqepHMtDXjSefMmeMLFy5sxlOLZOPZZ58ddPe5Y4+XUvRmNhu4B1gNDAK3u/tDRd+/cOFCenp6ynhqESlgZv1nO17Wlf5HwHFgHvBR4DEze97de0t6fBEpScPv6c2sA1gDrHf3IXd/EngE+KdGH1tEylfGB3lLgFF331lz7Hlgee03mdlaM+sxs56BgYESnlZE6lFG0U8HDo85dgjorD3g7pvcvdvdu+fOPeOzBRGZJGUU/RAwY8yxGcCREh5bREpWRtHvBNrM7MqaYysAfYgn0oIaLnp3HwY2A981sw4zWwV8Dnig0ccWkfKVdUfevwIXAPuAnwL/onadSGsqpU/v7vuBW8p4LBGZWLr3XiQzKnqRzKjoRTKjohfJjIpeJDMqepHMqOhFMqOiF8mMil4kMyp6kcyo6EUyo6IXyUxTlsCWyZfandjMGnr8kZGRMN7X11cYW7FiRUPPnfrZoviUKc297jWya3S9vzNd6UUyo6IXyYyKXiQzKnqRzKjoRTKjohfJjIpeJDPq02ei0T79/v37w/i9994bxi+88MK6YgDnnXdeGO/q6grjjdyD0Mg9AOPRyH0Cp06dqu85635GEfmrpKIXyYyKXiQzKnqRzKjoRTKjohfJjIpeJDPq02ei0X7ytm3bwvijjz4axi+//PLC2LFjx8Kxw8PDYXz+/Plh/NZbby2MdXR0hGNTPf5G1yE4fvx43Y/d3t5e13OWcqU3s61mdszMhqpfO8p4XBEpX5kv79e5+/Tq19ISH1dESqT39CKZKbPov2dmg2b2lJndMDZoZmvNrMfMegYGBkp8WhE5F2UV/TeBRcClwCbgV2a2uPYb3H2Tu3e7e/fcuXNLeloROVelFL27/8Hdj7j7iLvfDzwF3FzGY4tIuSbqPb0DjfUyRGRCNNynN7OZwLXA/wGjwD8C1wH/1uhjS3mmTp3a0Pjf//73Yfyll14K4ydOnCiMpeaF33LLLWH8mWeeCePr168vjK1atSoce/XVV4fxBQsWhPEdO+Lu9dNPP10Yu+6668KxS5YsCeNFyrg5px24C1gGnAT6gFvcfWcJjy0iJWu46N19AFhZQi4iMgnUpxfJjIpeJDMqepHMqOhFMqOptX9DoumzqWmavb29YfzJJ58M4xdddFEYP3ToUGHsueeeC8em4jfccEMYX7q0eP5XlBekf+49e/aE8dTy3Z/85CcLYz/84Q/Dsd/4xjfCeBFd6UUyo6IXyYyKXiQzKnqRzKjoRTKjohfJjIpeJDPW6NLI9eju7vaenp5Jf95WN5G/i1SffvXq1WE81cdPiX621FLO559/fkPPHS1znZpynJp6u2zZsjCe+tm2bNlSGPvzn/8cju3v7w/jZvasu3ePPa4rvUhmVPQimVHRi2RGRS+SGRW9SGZU9CKZUdGLZEbz6VtIo9seNyK169C0adPCeGdnZxh/7733CmPRds0Ahw8fDuMXXHBBGD9y5EhhLNWnf+yxx8L4448/HsZPnjwZxvfu3VsYi7bYboSu9CKZUdGLZEZFL5IZFb1IZlT0IplR0YtkRkUvkhn16QWA4eHhMJ7qN6fiM2bMKIyl7hFIxV9++eUwHvXiU2sYpH6u1D0EbW1xiU2ZUnzdffXVV8Ox9RrXld7M1plZj5mNmNl9Y2KfMrM+M3vPzJ4ws64JyVRESjHel/d7qexB/9+1B81sDrAZWA/MBnqAn5eZoIiUa1wv7919M4CZdQMLakL/APS6+y+r8Q3AoJktc/e+knMVkRI0+kHecuD5039x92FgV/X4+5jZ2upbhJ6BgYEGn1ZE6tVo0U8Hxu4AeAg4Y/aFu29y92537059MCMiE6fRoh8Cxn4sOwMontYkIk3VaNH3AitO/8XMOoDF1eMi0oLG9UGembVVv3cqMNXMpgGjwMPAf5jZGuAx4NvAC/oQrz6pnnEqHvV8U3PWX3nllTB+4YUXhvHUfPtjx47VPXb69OlhfHBwMIxfcsklhbFUn/3o0aNhfNasWWH83XffDePR/vQHDhwIx+7evTuMFxnvlf4O4CjwLeBL1T/f4e4DwBpgI3AAuBb4Ql2ZiMikGG/LbgOwoSD2GyDe5kNEWobuvRfJjIpeJDMqepHMqOhFMqOptS0ktQT2qVOn6n7sJ554Ioyn2j9R2wvSU3Oj6a2HDo29qfP9onYfpFt+0fLbqW2wU63O1M+9b9++MP6d73ynMLZ9+/ZwbGrabxFd6UUyo6IXyYyKXiQzKnqRzKjoRTKjohfJjIpeJDPq07eQVB8+ta1yZOnSpWE8NXV2ZGQkjKdyj6b97tmzJxyb2or6gx/8YBiPck/12aNtriG9PPeiRYvC+E9+8pPC2N133x2Ovfzyy8N4EV3pRTKjohfJjIpeJDMqepHMqOhFMqOiF8mMil4kM3+VffpoKehGl5FOxaNeeWo+fErUy27UypUrw3hn5xmbEr1Pahnq1Jz36Nyk+uyjo6NhPNVrT82Zj5x33nlhPHXvRCr3bdu2FcZSv5N66UovkhkVvUhmVPQimVHRi2RGRS+SGRW9SGZU9CKZack+fSNzsxvtlTdTarvon/3sZ2H8d7/7XWGso6MjHJta1z7Vhz9x4kQYb2sr/qc2Y8aMcGyq1x2taw8wNDRUGEvdG5G6PyEltdV19PgPPfRQOPZjH/tYXTmN60pvZuvMrMfMRszsvprjC83MzWyo5mt9XZmIyKQY75V+L3AX8GngbMuYzHT3+L9jEWkJ492ffjOAmXUDCyY0IxGZUGV9kNdvZm+a2b1mNuds32Bma6tvEXoGBgZKeloROVeNFv0gsBLoAq4BOoEHz/aN7r7J3bvdvTu1mKCITJyGPr139yGgp/rXd8xsHfCWmXW6e7yMqIg0Rdl9+tPzUtX/F2lR47rSm1lb9XunAlPNbBowSuUl/UHgFWAW8ANgq7vHG44nTOS88lTfNLVXen9/f2HsrbfeCsc++OBZ3/n8RWo/8tTa9NF+5ale+N69e8P4FVdcEcZT9wFEff433ngjHJua056aT3/TTTcVxqIePsCWLVvCeGo+/axZs8J4NNf/t7/9bTi2XuOtrjuAo8C3gC9V/3wHsAj4NXAEeBEYAW4tP00RKct4W3YbgA0F4Z+WlYyITDy99xbJjIpeJDMqepHMqOhFMtOSU2tfffXVMH777bcXxt58881w7DvvvBPG29vbw3g0hXTevHnh2FTrafbs2WE8tWVzNCU5tZzyRz7ykTAebakMcOONN4bx/fv3F8amTZsWjk1NOU555plnCmMHDx4Mxy5evDiMp1qhqa2uoxbxzp07w7H10pVeJDMqepHMqOhFMqOiF8mMil4kMyp6kcyo6EUy07Q+fdRT/upXvxqO3bVrV2EsWmoZ0n34VN81kpq2m8qt0a2Jo2XIduzYEY7duHFjGE9N673zzjvD+GWXXVb3Y3/+858P46leetTv3rNnTzg2dW9EamnwaLozxP8e58+fH46tl670IplR0YtkRkUvkhkVvUhmVPQimVHRi2RGRS+Smab06Q8fPhwu7/vyyy+H41esWFEYO3DgQDg2FX/77bfDeOT48eNhvLe3N4yn+s1XXnllGD98+HBhbMGCeAvC1atXh/FoTjrAmjVrwvjrr79eGIvyBti2bVsYf+SRR8J4dE9Iai5/ahvsVJ8+Jbp3I7X9d+q8FdGVXiQzKnqRzKjoRTKjohfJjIpeJDMqepHMqOhFMtOUPn1bWxtz584tjC9dujQcPzg4WBibPn16ODY1RznVx4/6slFekF4X/6qrrgrjqW20o/n4qa2kU2vyf+ITnwjjq1atCuMvvvhiYSxaBwDi7ZwBLr744rrHp9Y4SPXxR0ZGwnhqK2t3L4yl7vtIrQVQJHmlN7PzzeweM+s3syNm9pyZ3VQT/5SZ9ZnZe2b2hJl11ZWJiEyK8by8bwPeAK4HLqKyL/0vzGyhmc0BNgPrgdlAD/DzCcpVREqQfHnv7sO8f2/6R83sNeAa4GKg191/CWBmG4BBM1vm7n3lpysijTrnD/LMbB6wBOgFlgPPn45V/4PYVT0+dtxaM+sxs57U/mEiMnHOqejNrB14ELi/eiWfDoz9dOkQcMYnSu6+yd273b175syZ9eYrIg0ad9Gb2RTgAeA4sK56eAgYu3zsDCDeqlNEmmZcLTszM+AeYB5ws7ufnvPXC/xzzfd1AIurxwu1t7eHLbvK0xVbsmRJYWxoaCgcm9rK+gMf+EAYv+SSSwpjH/rQh8KxqamSqWmaqfZQ9LO/++674dho+imkW51//OMfw3jUSr3iiisaeu7U9Nfod5ZaEr3RJdVTy6Lv3r27MBa18wD+9Kc/hfEi473S/xi4CviMu9f+FA8DV5vZGjObBnwbeEEf4om0rvH06buArwEfBd42s6Hq123uPgCsATYCB4BrgS9MZMIi0pjxtOz6gcLX2+7+G2BZmUmJyMTRvfcimVHRi2RGRS+SGRW9SGaaMrW2vb2dSy+9tDB+2223heO///3vF8ZSy0QvX37GHcLvk5pKGfXCU3324eHhMJ7q6Y6OjobxaMvnVD85dW9EagvvRYsWhfFoimmqF56aYhrd8wHxlOTU73vWrFkNxVNTlqPzlloKPqqhiK70IplR0YtkRkUvkhkVvUhmVPQimVHRi2RGRS+Smab06VO+/OUvh/FrrrmmMLZx48Zw7EsvvRTGL7vssjAerfqTWmb65MmTYTzVj0716aPHT83NTvXpU7ml5vpH9yik7m9I5Z4Sje/qihdvTq3PkFqnYMqU+Lr62muvFcY+/vGPh2Ovv/76MF6YU12jROSvlopeJDMqepHMqOhFMqOiF8mMil4kMyp6kcxYoz3QenR3d/v27dsL46mecSP6+uLVub/+9a+H8f7+/sLY/v37w7GpteVTffzUuvnRnPXU73nBggVhvJG9CCDOLbW9eOq8pES5p9YZSN17kfqdfvaznw3j0foPqTUKUszsWXfvHntcV3qRzKjoRTKjohfJjIpeJDMqepHMqOhFMqOiF8lMcj69mZ0P/CdwIzAb2AXc7u7/a2YLgdeA2snS/+7ud47jcevJt2HLlsV7bT7++ON1P/bAwEAYP3jwYBjv7OwM4/v27Qvj0T7uqbXlZ8+eHcblb8d4FtFoA94Argd2AzcDvzCzD9d8z0x3j1d4EJGWkHx57+7D7r7B3V9391Pu/iiVq3vx8jUi0rLO+T29mc0DlgC9NYf7zexNM7vXzOYUjFtrZj1m1pN6GSwiE+ecit7M2oEHgfvdvQ8YBFYCXVSu/J3V+BncfZO7d7t7d2rvMRGZOONeGNPMpgAPAMeBdQDuPgT0VL/lHTNbB7xlZp3ufqTsZEWkceMqeqt81H4PMA+42d2LpnudnsqlVqBIixrvlf7HwFXAje7+l/2Uzexa4CDwCjAL+AGw1d2L9wb+G5Z629Lo25qoJScyXskrspl1AV8DPgq8bWZD1a/bgEXAr4EjwIvACHDrBOYrIg1KXundvR+I7qT5aXnpiMhE03tvkcyo6EUyo6IXyYyKXiQzKnqRzKjoRTKjohfJjIpeJDMqepHMqOhFMqOiF8mMil4kMyp6kcw0ZatqMxsAavd8nkNl6a1WpNzqo9zOXdl5dbn7GYs4NKXoz0jCrOds+2i3AuVWH+V27iYrL728F8mMil4kM61S9JuanUBAudVHuZ27ScmrJd7Ti8jkaZUrvYhMEhW9SGZU9CKZaWrRm9lsM3vYzIbNrN/MvtjMfGqZ2VYzO1azzv+OJuayrrr554iZ3Tcm9ikz6zOz98zsieo+BU3Ny8wWmpnXnLshM1s/WXlVczjfzO6p/rs6YmbPmdlNNfFmnrfC3Cbj3I17L7sJ8iMqe+PNo7KZxmNm9ry798bDJs06d/+vZicB7AXuAj4NXHD6YHWH4M3AV4BfAXcCPwf+rpl51Zjp7qOTlMtYbcAbwPXAbuBm4Bdm9mFgiOaetyi30ybu3Ll7U76ADioFv6Tm2APA3c3KaUx+W4GvNDuPMTndBdxX8/e1wNNjzulRYFmT81pIZV/DtmafszF5vgCsaZXzVpDbhJ+7Zr68XwKMuvvOmmPPA8ublM/ZfM/MBs3sKTO7odnJnMVyKucMAHcfBnbROuew38zeNLN7q69KmsbM5lH5N9dLi523MbmdNmHnrplFPx04PObYISp73LeCb1LZq+9SKjdN/MrMFjc3pTNMp3LOarXCORwEVgJdwDVU8nmwWcmYWXv1+e939z5a6LydJbcJP3fNLPohYMaYYzOobIbZdO7+B3c/4u4j7n4/8BSV916tpCXPobsPuXuPu4+6+zvAOmC1mTWjqKZQedt4vJoHtMh5O1tuk3Humln0O4E2M7uy5tgK3v8Sp5U48UaezdBL5ZwBYGYdwGJa7xyevu1zUv+9mZkB91D5oHiNu5+ohpp+3oLcxir93DWt6KvvozYD3zWzDjNbBXyOyv98TWVmM83s02Y2zczaqttyX0dlW+5m5NNmZtOAqcDU03kBDwNXm9maavzbwAvVl4lNy8vMrjWzpWY2xcwuBn4AbHX3sS+pJ9qPgauAz7j70ZrjTT1vUW6Tcu6a/GnqbGALMEyldfHFZuZTk9dcYDuVl3sHgW3A3zcxnw1U/sev/dpQjd0I9FH59HkrsLDZeQG3Aq9Vf69vAf8DzJ/kc9ZVzecYlZfzp79ua4HzVpjbZJw7TbgRyYxuwxXJjIpeJDMqepHMqOhFMqOiF8mMil4kMyp6kcyo6EUy8//RrfIGPEFg3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "print (\"Shape of full train and test sets\", X_train_full.shape, y_train_full.shape, X_test.shape, y_test.shape)\n",
    "X_train, X_valid = X_train_full[:-35000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-35000], y_train_full[-5000:]\n",
    "\n",
    "plt.imshow(X_train_full[0], cmap=\"Greys\")\n",
    "print (\"item0\", y_train_full[0])\n",
    "print (\"Shape of train and valid sets\", X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)\n",
    "\n",
    "#Normalise the features set with mean and standard deviations\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_valid = (X_valid - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "#Add an extra dimension for channels and compatibility to tools\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print (\"Shape of features\", X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image is 28x28 and has a single channel\n",
    "- MaxPooling of 2 reduces spacial dimension by 2 keeping memory requirements in control\n",
    "- Increase the number of filters (doubling)as we go deeper to create combine lower level feature to higher level features\n",
    "- We flatten the data and feed to the dense layers in the end. Makes it into a single dimensional array that can be input to dense layers\n",
    "- There is 50% normalisation to reduce overfitting\n",
    "- And finally a 10 output dense layer with softmax to bring it down to 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "#Create a function with which we can more easily add convolution layers\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]), #Based on input size\n",
    "    keras.layers.MaxPooling2D(pool_size=2), #Same maxpooling applied regularly\n",
    "    DefaultConv2D(filters=128),  \n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 63s 3ms/sample - loss: 0.9632 - accuracy: 0.6577 - val_loss: 0.5330 - val_accuracy: 0.8158\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 61s 2ms/sample - loss: 0.5470 - accuracy: 0.8086 - val_loss: 0.3922 - val_accuracy: 0.8584\n",
      "10000/10000 [==============================] - 8s 758us/sample - loss: 0.4003 - accuracy: 0.8555\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=2, validation_data=(X_valid, y_valid))\n",
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4003287184238434, 0.8555]\n"
     ]
    }
   ],
   "source": [
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[10:20] # pretend we have new images\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 7 3 4 1 2 4 8 0]\n"
     ]
    }
   ],
   "source": [
    "#Print actual data from test\n",
    "print (y_test[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 5 3 4 1 2 4 8 0]\n"
     ]
    }
   ],
   "source": [
    "#Print the output of the predicted set\n",
    "print (np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
